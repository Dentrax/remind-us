package rss

import (
	"context"
	"fmt"
	"net/url"
	"regexp"
	"strconv"
	"strings"
	"time"

	"github.com/Dentrax/remind-us/pkg/config"
	"github.com/Dentrax/remind-us/pkg/integrations"
	"github.com/hako/durafmt"
	"github.com/mmcdole/gofeed"
	"github.com/pkg/errors"
	"github.com/slack-go/slack"
	"golang.org/x/sync/errgroup"
)

var errLoad = errors.New("rss is not loaded")

type RSS struct {
	integrations.Integration

	// result stores fetched sources
	// from remote.
	result map[string]*gofeed.Feed

	// sinceMap stores time.Duration
	// for each given RSS URL.
	//
	// map: K: RSS Source URL, V: time.Duration
	sinceMap map[string]time.Duration

	// sourceConfigMap stores RSSSourceConfig config
	// for each given RSS URL.
	sourceConfigMap map[string]config.RSSSourceConfig

	// matchTitleRegExpMap stores compiled RegExps
	// that generated by Validate function. Since
	// we use `regexp.MatchString` during Load phase,
	// we better not to compile same RegExp again.
	//
	// map: K: RSS Source URL, V: Compiled 'MatchTitle' RegExp Array
	matchTitleRegExpMap map[string][]*regexp.Regexp

	// initialTime stores the time.Now just before
	// the module is loaded. It would be inconsistent
	// to get the time.Now after requests all RSSs concurrently.
	// Because we would ignore the time diff between, otherwise.
	// Will set from main.
	InitialTime time.Time

	// config stores the config of RSS
	config *config.RSSIntegrationConfig
}

func (r *RSS) Name() string {
	return "RSS"
}

func (r *RSS) Enabled(config config.Integrations) bool {
	if config.RSS == nil {
		return false
	}

	v, _ := strconv.ParseBool(config.RSS.Enabled)

	return v
}

func (r *RSS) Validate(c config.Integrations) error {
	sinceMap := make(map[string]time.Duration, len(c.RSS.Sources))
	matchTitleRegExpMap := make(map[string][]*regexp.Regexp, len(c.RSS.Sources))

	// err same url exist
	for _, source := range c.RSS.Sources {
		_, err := url.ParseRequestURI(source.URL)
		if err != nil {
			return errors.Wrapf(err, "incorrect URL pattern: '%s'", source.URL)
		}

		since, err := time.ParseDuration(source.Since)
		if err != nil {
			return errors.Wrapf(err, "incorrect 'since' pattern: '%s'", source.Since)
		}

		sinceMap[source.URL] = since

		rgxs := make([]*regexp.Regexp, len(source.MatchTitle.Regexes))

		for i, regex := range source.MatchTitle.Regexes {
			re, err := regexp.Compile(regex)
			if err != nil {
				return errors.Wrapf(err, "incorrect RegExp pattern: '%s'", regex)
			}

			rgxs[i] = re
		}

		matchTitleRegExpMap[source.URL] = rgxs
	}

	r.matchTitleRegExpMap = matchTitleRegExpMap
	r.sinceMap = sinceMap
	r.Validated = true

	return nil
}

func (r *RSS) Load(c config.Integrations) error {
	fp := gofeed.NewParser()

	sourceMap := make(map[string]config.RSSSourceConfig, len(c.RSS.Sources))
	feeds := make(map[string]*gofeed.Feed, len(c.RSS.Sources))

	for _, source := range c.RSS.Sources {
		sourceMap[source.URL] = source
	}

	g, ctx := errgroup.WithContext(context.Background())

	for _, s := range c.RSS.Sources {
		u := s.URL

		g.Go(func() error {
			feed, err := fp.ParseURLWithContext(u, ctx)
			if err != nil {
				return err
			}
			feeds[u] = feed
			return nil
		})
	}

	if err := g.Wait(); err != nil {
		return errors.Wrapf(err, "Could not fetch all RSS sources")
	}

	r.sourceConfigMap = sourceMap
	r.result = feeds
	r.config = c.RSS
	r.Loaded = true

	return nil
}

func (r *RSS) GenerateSlackMessage(options integrations.GenerateMessageOptions) (*slack.WebhookMessage, error) {
	if !r.Loaded {
		return nil, errLoad
	}

	timeParsed := func(published, updated *time.Time) *time.Time {
		if published != nil {
			return published
		}

		return updated
	}

	getTime := func(published, updated *time.Time) *time.Time {
		var t *time.Time
		if published != nil {
			t = published
		} else if updated != nil {
			t = updated
		}

		return t
	}

	attachments := make([]slack.Attachment, 0, len(r.result))

	for k, v := range r.result {
		items := make([]*gofeed.Item, 0, len(v.Items))

		for _, i := range v.Items {
			flag := false

			// Title matcher
			// flag presents the whether we proceed with the current item

			// For Contains
			for _, c := range r.sourceConfigMap[k].MatchTitle.Contains {
				// case-insensitive search in title
				if strings.Contains(strings.ToLower(i.Title), strings.ToLower(c)) {
					flag = true
					break
				}
			}

			// We do not want to scan whole RegExp map if it is already marked
			if !flag {
				// For Regexes
				for _, re := range r.matchTitleRegExpMap[k] {
					if re.MatchString(i.Title) {
						flag = true
						break
					}
				}
			}

			if flag {
				since := r.InitialTime.Sub(*timeParsed(i.PublishedParsed, i.UpdatedParsed))

				if since >= r.sinceMap[k] {
					continue
				}

				items = append(items, i)
			}
		}

		if len(items) == 0 {
			continue
		}

		fields := make([]slack.AttachmentField, len(items))

		for i, item := range items {
			// Some RSS feeds stores their official link in GUID field (i.e. HN)
			// we must check which one is valid
			getLink := func(link, guid string) string {
				if strings.HasPrefix(guid, "http") {
					if _, err := url.ParseRequestURI(guid); err == nil {
						return guid
					}
				}

				if _, err := url.ParseRequestURI(link); err == nil {
					return link
				}

				return v.Link
			}(item.Link, item.GUID)

			// Some RSS feeds use updated field only, to prevent this, we should check both
			getTimeString := func(published, updated *time.Time) string {
				t := getTime(published, updated)

				if t != nil {
					return fmt.Sprintf("(%s ago)", durafmt.Parse(r.InitialTime.Sub(*t)).LimitFirstN(1).String())
				}

				return ""
			}

			fields[i] = slack.AttachmentField{
				Title: "",
				Value: fmt.Sprintf("â€¢ <%s|%s> %s", getLink, item.Title, getTimeString(item.PublishedParsed, item.UpdatedParsed)),
				Short: false,
			}
		}

		attachments = append(attachments, slack.Attachment{
			Color:      "good",
			AuthorName: v.Title,
			AuthorLink: v.Link,
			Fields:     fields,
		})
	}

	return &slack.WebhookMessage{
		Attachments: attachments,
	}, nil
}
